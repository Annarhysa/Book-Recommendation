{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid Recommendation using\n",
    "a) Collaborative Filtering Model\n",
    "\n",
    "b) Content-based Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from random import randint\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.linalg import svds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "FORMULA\n",
    "X(NORMALIZED) = (X - Xminimum)/(Xmaximum - Xminimum)\n",
    "\n",
    " min_val = min(data)\n",
    "    if min_val < 0:\n",
    "        data = [x + abs(min_val) for x in data]\n",
    "    max_val = max(data)\n",
    "    \n",
    "    return [x/max_val for x in data]\n",
    "'''\n",
    "#normalizing the input between 0s and 1s\n",
    "def normalize(data):    \n",
    "    return (data - np.min(data)/ (np.max(data)- np.min(data)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "CREATING FUNCTIONS FOR CONTENT BASED RECOMMENDATION MODELS\n",
    "\n",
    "''' \n",
    "\n",
    "#performing one hot encoding\n",
    "def encoding(df, column):\n",
    "    new = pd.get_dummies(df[column])\n",
    "    new.reset_index(drop = True, inplace = True)\n",
    "    return pd.concat([df, new], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "CREATING FRUNCTION FOR COLLABORATIVE FILTER MODELLING\n",
    "'''\n",
    "\n",
    "def svd(mat, df, factors):\n",
    "    if not 1<= factors < min(mat.shape):\n",
    "        raise ValueError(\"Must be 1 <= factors < min(mat.shape)\")\n",
    "    \n",
    "    #matrix factorization\n",
    "    u,s,v = svds(mat, k = factors)\n",
    "    s = np.diag(s)\n",
    "\n",
    "    #calculating the prediction ratings\n",
    "    pred = np.dot(np.dot(u,s),v)\n",
    "    pred = normalize(pred) #normalizing the predictions\n",
    "\n",
    "    new_df = pd.DataFrame(pred, columns = df.columns, index = list(df.index) ).transpose()\n",
    "\n",
    "    return new_df\n",
    "\n",
    "def similarity(v1, v2):\n",
    "        return np.sum(np.dot(v1,v2)/ np.cross(v1,v2)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" \\nCreating a Content based recommendation syatem as the base system\\n\\nclass Recommender():\\n    def __init__(self,df):\\n        self.df = df\\n    \\n    def similarity(self, v1, v2):\\n        return np.sum(np.dot(v1,v2)/ np.cross(v1,v2)) \\n    \\n    def recommend(self, book_id, rec):\\n        ip = self.df.loc[book_id].values\\n        self.df['sim'] = self.df.apply(lambda x: self.similarity(ip, x.values), axis =1)\\n        \\n        return self.df.nlargest(columns = 'sim', n = rec)\\n        \\n\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "Creating a Content based recommendation syatem as the base system\n",
    "\n",
    "class Recommender():\n",
    "    def __init__(self,df):\n",
    "        self.df = df\n",
    "    \n",
    "    \n",
    "    \n",
    "    def recommend(self, book_id, rec):\n",
    "        ip = self.df.loc[book_id].values\n",
    "        self.df['sim'] = self.df.apply(lambda x: self.similarity(ip, x.values), axis =1)\n",
    "        \n",
    "        return self.df.nlargest(columns = 'sim', n = rec)\n",
    "        \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" \\ndf['num_pages_norm'] = normalize(df['num_pages'].values)\\ndf['book_rating_norm'] = normalize(df['book_rating'].values)\\ndf['book_price_norm'] = normalize(df['book_price'].values)\\n\\n\\ndf = encoding(df = df, column = 'publish_year')\\ndf = encoding(df = df, column = 'book_genre')\\ndf = encoding(df = df, column = 'text_lang')\\n\\n#dropping redndant columns\\ncols = ['publish_year', 'book_genre', 'num_pages', 'book_rating', 'book_price', 'text_lang']\\ndf.drop(columns = cols, inplace = True)\\n\\n\""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "df['num_pages_norm'] = normalize(df['num_pages'].values)\n",
    "df['book_rating_norm'] = normalize(df['book_rating'].values)\n",
    "df['book_price_norm'] = normalize(df['book_price'].values)\n",
    "\n",
    "\n",
    "df = encoding(df = df, column = 'publish_year')\n",
    "df = encoding(df = df, column = 'book_genre')\n",
    "df = encoding(df = df, column = 'text_lang')\n",
    "\n",
    "#dropping redndant columns\n",
    "cols = ['publish_year', 'book_genre', 'num_pages', 'book_rating', 'book_price', 'text_lang']\n",
    "df.drop(columns = cols, inplace = True)\n",
    "\n",
    "''' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "CREATING THE FINAL HYBRID MODEL\n",
    "\n",
    "''' \n",
    "\n",
    "def hybrid(reader_id, book_id, data, n_recs, cosine, svd_model):\n",
    "\n",
    "    # similarity values\n",
    "\n",
    "    s = list(enumerate(cosine[int(book_id)]))\n",
    "    s = sorted(s, key = lambda x:x[1], reverse = True)\n",
    "\n",
    "    # metadeta\n",
    "    index = [i[0] for i in s]\n",
    "    books = data.iloc[index][['book_id', 'book_rating', 'num_pages', 'publish_year', 'book_price', 'reader_id']]\n",
    "\n",
    "    #applying the model\n",
    "\n",
    "    books['predicted'] = books.apply(lambda x: svd_model.predict(reader_id, x['book_id'], x['book_rating']).est, axis = 1)\n",
    "    \n",
    "    #sorting\n",
    "\n",
    "    books = books.sort_values('est', ascending = False)\n",
    "\n",
    "    return books.head(n_recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (28936,3000) and (28936,3000) not aligned: 3000 (dim 1) != 28936 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 11\u001b[0m\n\u001b[0;32m      7\u001b[0m matrix_1 \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mpivot_table(columns \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mbook_id\u001b[39m\u001b[39m'\u001b[39m, index \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mreader_id\u001b[39m\u001b[39m'\u001b[39m, values \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mbook_rating\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mfillna(\u001b[39m0\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[39m#similarities\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m cosine \u001b[39m=\u001b[39m similarity(matrix_1, matrix_1)\n\u001b[0;32m     12\u001b[0m cosine \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(cosine, index \u001b[39m=\u001b[39m matrix_1\u001b[39m.\u001b[39mindex, cloumns \u001b[39m=\u001b[39m matrix_1\u001b[39m.\u001b[39mindex)\n\u001b[0;32m     14\u001b[0m \u001b[39m# Collaborative filtering\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[8], line 24\u001b[0m, in \u001b[0;36msimilarity\u001b[1;34m(v1, v2)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msimilarity\u001b[39m(v1, v2):\n\u001b[1;32m---> 24\u001b[0m         \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39msum(np\u001b[39m.\u001b[39;49mdot(v1,v2)\u001b[39m/\u001b[39m np\u001b[39m.\u001b[39mcross(v1,v2))\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (28936,3000) and (28936,3000) not aligned: 3000 (dim 1) != 28936 (dim 0)"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    data = df\n",
    "\n",
    "    #curating content\n",
    "\n",
    "    matrix_1 = df.pivot_table(columns = 'book_id', index = 'reader_id', values = 'book_rating').fillna(0)\n",
    "\n",
    "    #similarities\n",
    "\n",
    "    cosine = similarity(matrix_1, matrix_1)\n",
    "    cosine = pd.DataFrame(cosine, index = matrix_1.index, cloumns = matrix_1.index)\n",
    "\n",
    "    # Collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(n_books = 3000, n_genres = 10, n_authors = 450, n_publishers = 50, n_readers = 30000, dataset_size = 100000):\n",
    "    \n",
    "    d = pd.DataFrame(\n",
    "        {\n",
    "            'book_id' : [randint(1, n_books) for _ in range(dataset_size)],\n",
    "            'author_id' : [randint(1, n_authors) for _ in range(dataset_size)],\n",
    "            'book_genre' : [randint(1, n_genres) for _ in range(dataset_size)],\n",
    "            'reader_id' : [randint(1, n_readers) for _ in range(dataset_size)],\n",
    "            'num_pages' : [randint(75, 700) for _ in range(dataset_size)],\n",
    "            'book_rating' : [randint(1, 10) for _ in range(dataset_size)],\n",
    "            'publisher_id' : [randint(1, n_publishers) for _ in range(dataset_size)],\n",
    "            'publish_year' : [randint(2000, 2021) for _ in range(dataset_size)],\n",
    "            'book_price' : [randint(1, 200) for _ in range(dataset_size)],\n",
    "            'text_lang' : [randint(1,7) for _ in range(dataset_size)]\n",
    "        }\n",
    "    ).drop_duplicates()\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_data(dataset_size = 100000)\n",
    "df.to_csv('data.csv', index = False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by=['book_id'], ascending = True)\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
